---
layout: post
title:  "使用三台centos安装hadoop"
date:   2021-1-22
categories: big data
---

## Hadoop简介

Hadoop 是一个适合大数据的分布式存储和计算平台。 如前所述，狭义上说Hadoop就是一个框架平台，广义上讲Hadoop代表大数据的一个技术生态  
圈，包括很多其他软件框架

### Hadoop生态圈技术栈

1. Hadoop(HDFS + MapReduce + Yarn)   
2. Hive 数据仓库工具  
3. HBase 海量列式非关系型数据库  
4. Flume 数据采集工具  
5. Sqoop ETL工具  
6. Kafka 高吞吐消息中间件

### Hadoop的特点
![](/resource/hadoop1/assets/D11ED418-49FF-4A18-906D-09879D05A4C5.png)

### Hadoop的发行版本

企业中主要用到的三个版本分别是:Apache Hadoop版本(最原始的，所有发行版均基于这个版 本进行改进)、Cloudera版本(Cloudera’s Distribution Including Apache Hadoop，简称“CDH”)、 Hortonworks版本(Hortonworks Data Platform，简称“HDP”)

- Apache Hadoop 原始版本
  官网地址:http://hadoop.apache.org/   
  * 优点:拥有全世界的开源贡献，代码更新版本比较快，学习非常方便   
  * 缺点:版本的升级，版本的维护，以及版本之间的兼容性  
  * Apache所有软件的下载地址(包括各种历史版本):http://archive.apache.org/dist/

- ClouderaManager CDH版本
  — 生产环境使用   
  官网地址:https://www.cloudera.com/  
  Cloudera主要是美国一家大数据公司在Apache开源Hadoop的版本上，通过自己公司内部的各种 补丁，实现版本之间的稳定运行，大数据生态圈的各个版本的软件都提供了对应的版本，解决了版 本的升级困难，版本兼容性等各种问题，生产环境强烈推荐使用

- HortonWorks HDP版本
  — 生产环境使用  
  官网地址:https://hortonworks.com/ hortonworks主要是雅虎主导Hadoop开发的副总裁，带领二十几个核心成员成立Hortonworks， 核心产品软件HDP(ambari)，HDF免费开源，并且提供一整套的web管理界面，供我们可以通 过web界面管理我们的集群状态，web管理界面软件HDF网址(http://ambari.apache.org/)

### Hadoop的优点

* Hadoop具有存储和处理数据能力的高可靠性。   
* Hadoop通过可用的计算机集群分配数据，完成存储和计算任务，这些集群可以方便地扩展到数以千计的节点中，具有高扩展性。  
* Hadoop能够在节点之间进行动态地移动数据，并保证各个节点的动态平衡，处理速度非常快，具有高效性。   
* Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配，具有高容错性。

### Hadoop的缺点

* Hadoop不适用于低延迟数据访问。   
* Hadoop不能高效存储大量小文件。   
* Hadoop不支持多用户写入并任意修改文件。

## Apache Hadoop的重要组成

Hadoop=HDFS(分布式文件系统)+MapReduce(分布式计算框架)+Yarn(资源协调框架)+Common模块

### 1. Hadoop HDFS
![](/resource/hadoop1/assets/D02DA1FB-6611-4213-9C8A-6DCB28E94E3D.png)

(Hadoop Distribute File System )一个高可靠、高吞吐量的分布式文件系统。  
数据切割、制作副本、分散储存  
  
比如:100T数据存储，  
“分而治之” 分:拆分--》数据切割，100T数据拆分为10G一个数据块由一个电脑节点存储这个数据块。  
  
注：NN，2NN,DN这些既是角色名称，进程名称，代指电脑节点名称!!

- NameNode(nn)
  存储文件的元数据，比如文件名、文件目录结构、文件属性(生成时间、副  
  本数、文件权限)，以及每个文件的块列表和块所在的DataNode等。

- SecondaryNameNode(2nn)
  辅助NameNode更好的工作，用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据快照。

- DataNode(dn)
  在本地文件系统存储文件块数据，以及块数据的校验

### 2. Hadoop MapReduce
![](/resource/hadoop1/assets/480FCD21-93CF-4C2D-B76D-05EC501E146B.png)

一个分布式的离线并行计算框架  
拆解任务、分散处理、汇整结果  
  
MapReduce计算 = Map阶段 + Reduce阶段  
* Map阶段就是“分”的阶段，并行处理输入数据;   
* Reduce阶段就是“合”的阶段，对Map阶段结果进行汇总;

### 3. Hadoop YARN
![](/resource/hadoop1/assets/E4BD86C3-3A7B-48DC-8B24-DA26E5A78012.png)

作业调度与集群资源管理的框架  
Yarn中有如下几个主要角色，同样，既是角色名、也是进程名，也指代所在计算机节点名称。  
  
ResourceManager是老大，NodeManager是小弟，ApplicationMaster是计算任务专员

- ResourceManager(rm)
  处理客户端请求、启动/监控ApplicationMaster、监控NodeManager、资源分配与调度

- NodeManager(nm)
  单个节点上的资源管理、处理来自ResourceManager的命令、处理来自  
  ApplicationMaster的命令

- ApplicationMaster(am)
  数据切分、为应用程序申请资源，并分配给内部任务、任务监控与容  
  错

- Container
  对任务运行环境的抽象，封装了CPU、内存等多维资源以及环境变量、启动命令等任务运行相关的信息。

### 4. Hadoop Common

支持其他模块的工具模块(Configuration、RPC、序列化机制、日志操作)

## 完全分布式集群搭建

Hadoop框架是采用Java语言编写，需要java环境(jvm)  
JDK版本:必须使用JDK8版本  
  
* Hadoop搭建方式  
	* 单机模式:单节点模式，非集群，生产不会使用这种方式   
	* 单机伪分布式模式:单节点，多线程模拟集群的效果，生产不会使用这种方式  
	* 完全分布式模式:多台节点，真正的分布式Hadoop集群的搭建(生产环境建议使用这种方式)

### 1. 虚拟机环境准备

- 1. 使用三台centos7的虚拟机(静态IP，关闭防火墙，修改主机名，配置免密登录，集群时间同步)

- 2. 创建文件夹目录
  ```sh  
  mkdir -p /opt/lagou/software --软件安装包存放目录   
  mkdir -p /opt/lagou/servers --软件安装目录  
  ```

- 3.下载hadoop源码
  https://archive.apache.org/dist/hadoop/common/hadoop-2.9.2/

- 4.上传hadoop安装文件到/opt/lagou/software

### 2. 集群规划

| 框架 | centos7-1 | centos7-2 | centos7-3 |  
|----|----|----|----|  
| HDFS | NameNode、DataNode | DataNode |SecondaryNameNode、DataNode |  
|YARN| NodeManager|NodeManager|NodeManager、ResourceManager|

### 3.安装Hadoop

- 基本安装

	- 1. 解压hadoop安装包
	  登录centos7-1节点;进入/opt/lagou/software,解压安装文件到/opt/lagou/servers  
	    
	  ```sh  
	  tar -zxvf hadoop-2.9.2.tar.gz -C /opt/lagou/servers  
	  ```

	- 2. 添加hadoop环境变量到 /etc/profile
	  ```  
	  #HADOOP_HOME  
	  # 这个路径可能需要更改为当前实际目录  
	  export HADOOP_HOME=/opt/lagou/servers/hadoop-2.9.2  
	  export PATH=$PATH:$HADOOP_HOME/bin  
	  export PATH=$PATH:$HADOOP_HOME/sbin  
	  ```

	- 3. source /etc/profile
	  使环境变量生效

	- 4. hadoop version
![](/resource/hadoop1/assets/3B235E11-BA13-4CC4-A413-4C798296C3C4.png)

	  验证hadoop

	- 5.hadoop目录<br>
![](/resource/hadoop1/assets/899E397D-69A3-437B-B55B-917422B33E63.png)
	  1. bin目录:对Hadoop进行操作的相关命令，如hadoop,hdfs等  
	  2. etc目录:Hadoop的配置文件目录，入hdfs-site.xml,core-site.xml等 3. lib目录:Hadoop本地库(解压缩的依赖)  
	  4. sbin目录:存放的是Hadoop集群启动停止相关脚本，命令  
	  5. share目录:Hadoop的一些jar,官方案例jar，文档等

- 集群配置
  Hadoop集群配置 = HDFS集群配置 + MapReduce集群配置 + Yarn集群配置

	- HDFS集群配置
	  所有xml文件的配置信息都要写在  
	  <configuration></configuration>内部

		- 1. 将JDK路径明确配置给HDFS(修改hadoop-env.sh)
		  跳转到配置文件目录  
		  ```sh  
		  cd /opt/lagou/servers/hadoop-2.9.2/etc/hadoop  
		  ```  
		    
		  ```sh  
		  vim hadoop-env.sh  
		    
		    
		  export JAVA_HOME=/opt/lagou/servers/jdk1.8.0_231  
		  ```

		- 2. 指定NameNode节点以及数据存储目录(修改core-site.xml)

		  ```sh  
		  vim core-site.xml  
		    
		  <configuration>  
		  <!-- 指定HDFS中NameNode的地址 -->  
		  <property>  
		      <name>fs.defaultFS</name>  
		      <value>hdfs://centos7-1:9000</value>  
		  </property>  
		    
		  <!-- 指定Hadoop运行时产生文件的存储目录 -->   
		  <property>  
		      <name>hadoop.tmp.dir</name>  
		      <value>/opt/lagou/servers/hadoop-2.9.2/data/tmp</value>  
		  </property>  
		  </configuration>  
		    
		  ```  
		    
		  可以在官方文档查看配置的解释  
		    
		  [core-site.xml的默认配置](https://hadoop.apache.org/docs/r2.9.2/hadoop-project-dist/hadoop-common/core-default.xml)

		- 3. 指定SecondaryNameNode节点(修改hdfs-site.xml)

		  ```xml  
		  vim hdfs-site.xml  
		    
		    
		  <configuration>  
		    
		  <!-- 指定Hadoop辅助名称节点主机配置 -->  
		  <property>  
		  	<name>dfs.namenode.secondary.http-address</name>  
		        <value>centos7-3:50090</value>  
		  </property>  
		    
		  <!--副本数量 -->  
		  <property>  
		          <name>dfs.replication</name>  
		          <value>3</value>  
		  </property>  
		    
		  </configuration>  
		    
		  ```  
		    
		  [官方默认配置](https://hadoop.apache.org/docs/r2.9.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml)

		- 4. 指定DataNode从节点(修改etc/hadoop/slaves文件，每个节点配置信息占一行)

		  ```sh  
		  vim slaves  
		    
		  centos7-1  
		  centos7-2  
		  centos7-3  
		  ```  
		    
		  *注意:该文件中添加的内容结尾不允许有空格，文件中不允许有空行。*

	- MapReduce集群配置

		- 1. 将JDK路径明确配置给MapReduce(修改mapred-env.sh)

		  ```sh  
		  vim mapred-env.sh  
		    
		  export JAVA_HOME=/opt/lagou/servers/jdk1.8.0_231  
		  ```

		- 2. 指定MapReduce计算框架运行Yarn资源调度框架(修改mapred-site.xml)

		  ```xml  
		    
		  mv mapred-site.xml.template mapred-site.xml  
		  vim mapred-site.xml  
		    
		  <!-- 指定MR运行在Yarn上 --> <property>  
		          <name>mapreduce.framework.name</name>  
		          <value>yarn</value>  
		  </property>  
		  ```  
		    
		  [mapred-site.xml默认配置](https://hadoop.apache.org/docs/r2.9.2/hadoop-mapreduce-client/hadoop-mapreduce-  
		  client-core/mapred-default.xml)

	- Yarn集群配置

		- 1. 将JDK路径明确配置给Yarn(修改yarn-env.sh)

		  ```sh  
		  vim yarn-env.sh  
		    
		  export JAVA_HOME=/opt/lagou/servers/jdk1.8.0_231  
		  ```

		- 2. 指定ResourceManager老大节点所在计算机节点(修改yarn-site.xml)

		  ```xml  
		  vim yarn-site.xml  
		    
		  <!-- 指定YARN的ResourceManager的地址 -->   
		  <property>  
		  	<name>yarn.resourcemanager.hostname</name>  
		  	<value>centos7-3</value>  
		  </property>  
		    
		  <!-- Reducer获取数据的方式 --> <property>  
		          <name>yarn.nodemanager.aux-services</name>  
		          <value>mapreduce_shuffle</value>  
		  </property>  
		  ```  
		    
		  [yarn-site.xml的默认配置](https://hadoop.apache.org/docs/r2.9.2/hadoop-yarn/hadoop-yarn-common/yarn-default.xml)

		- 3. 指定NodeManager节点(会通过slaves文件内容确定)

	- 修改hadoop文件群组
	  Hadoop安装目录所属用户和所属用户组信息，默认是501 dialout，而我们操作Hadoop集群的用户使 用的是虚拟机的root用户，  
	  所以为了避免出现信息混乱，修改Hadoop安装目录所属用户和用户组!!  
	    
	  ```sh  
	  chown -R root:root /opt/lagou/servers/hadoop-2.9.2  
	  ```

- 分发配置

	- 安装rsync
	  rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。   
	  rsync和scp区别:用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。  
	    
	  > 三台虚拟机安装rsync (执行安装需要保证机器联网)  
	  ```sh  
	   yum install -y rsync  
	  ```  
	    
	  基本语法  
	  ```sh  
	  rsync   -rvl    $pdir/$fname        $user@$host:$pdir/$fname  
	    
	  命令 选项参数 要拷贝的文件路径/名称 目的用户@主机:目的路径/名称  
	  ```  
	  `-r` 递归  
	  `-v` 显示复制过程  
	  `-l` 拷贝符号连接

	- 集群分发脚本编写
	  需求:循环复制文件到集群所有节点的相同目录下  
	    
	  ```sh  
	   vim  /usr/local/bin/rsync-script  
	    
	  #!/bin/bash  
	    
	  #1 获取命令输入参数的个数，如果个数为0，直接退出命令   
	  paramnum=${#}  
	  if((paramnum==0));then  
	  echo no params;  
	  exit;   
	  fi  
	    
	    
	  #2 根据传入参数获取文件名称   
	  p1=$1   
	  file_name=`basename $p1`   
	  echo fname=$file_name  
	    
	  #3 获取输入参数的绝对路径  
	  pdir=`cd -P $(dirname $p1); pwd`  
	  echo pdir=$pdir  
	    
	  #4 获取用户名称  
	  user=`whoami`  
	    
	    
	  #5 循环执行rsync  
	  for((host=1; host<4; host++)); do  
	  echo ------------------- centos7-$host --------------  
	   rsync -rvl $pdir/$file_name $user@centos7-$host:$pdir  
	  done  
	  ```

	- 修改脚本 rsync-script 具有执行权限
	  ```ssh  
	  chmod 777 rsync-script  
	  ```

	- 调用脚本分发Hadoop安装目录到其它节点
	  ```sh  
	  rsync-script /opt/lagou/servers/hadoop-2.9.2  
	  ```

### 4. 启动集群

注意: 如果集群是第一次启动，需要在Namenode所在节点格式化NameNode，非第一次不用执行格 式化Namenode操作!!

- 单点启动

	- 1. 格式化namenode
	  如果集群是第一次启动，需要在Namenode所在节点格式化NameNode，非第一次不用执行格 式化Namenode操作!!  
	    
	  ```sh  
	  [root@centos7-1 hadoop] hadoop namenode -format  
	  ```

		- 
![](/resource/hadoop1/assets/E3E0A668-481C-4403-84FF-5DB3D37B5574.png)

	- 2. 在centos7-1上启动NameNode
	  ```sh  
	  [root@centos7-1 hadoop]# hadoop-daemon.sh start namenode  
	  # 查看是否启动成功  
	  [root@centos7-1 hadoop]# jps  
	  ```

	- 3. 在centos7-1、centos7-2以及centos7-3上分别启动DataNode
	  ```sh  
	  hadoop-daemon.sh start datanode  
	  ```

	- 4. web端查看HDFS界面
	  nameNode所在机器的域名，或者ip  
	  [[http://centos7-1:50070]](http://centos7-1:50070)

		- 
![](/resource/hadoop1/assets/63D9CCE9-4E82-44D2-ABBE-B9EC6FE4705D.png)

	- 5. Yarn集群单节点启动
	  centos7-3  
	    
	  ```sh  
	  [root@centos7-3 hadoop-2.9.2] yarn-daemon.sh start resourcemanager  
	  ```  
	    
	  centos7-1、centos7-2、centos7-3  
	  ```sh  
	  yarn-daemon.sh start nodemanager  
	  ```

- 集群启动

	- 1. 格式化namenode
	  如果集群是第一次启动，需要在Namenode所在节点格式化NameNode，非第一次不用执行格 式化Namenode操作!!  
	    
	  ```sh  
	  [root@centos7-1 hadoop] hadoop namenode -format  
	  ```

		- 
![](/resource/hadoop1/assets/E3E0A668-481C-4403-84FF-5DB3D37B5574.png)

	- 2. 启动HDFS
	  centos7-1  
	    
	  ```sh  
	  [root@centos7-1 sbin]  /opt/lagou/servers/hadoop-2.9.2/sbin/start-dfs.sh  
	  ```

	- 3. 启动YARN
	  centos7-3  
	    
	  ```sh  
	  [root@centos7-3 sbin]  /opt/lagou/servers/hadoop-2.9.2/sbin/start-yarn.sh  
	  ```  
	    
	  注意:NameNode和ResourceManger不是在同一台机器，不能在NameNode上启动 YARN，应该 在ResouceManager所在的机器上启动YARN。

- 停止命令

	- 1. 分别启动/停止HDFS组件
	  ```sh  
	  hadoop-daemon.sh  start / stop  namenode / datanode / secondarynamenode  
	  ```

	- 2. 启动/停止YARN
	  ```sh  
	  yarn-daemon.sh  start / stop  resourcemanager / nodemanager  
	  ```

	- 3. 整体启动/停止HDFS
	  ```sh  
	  start-dfs.sh  /  stop-dfs.sh  
	  ```

	- 4. 整体启动/停止YARN
	  ```sh  
	  start-yarn.sh  /  stop-yarn.sh  
	  ```

### 5. 集群测试

- 1. HDFS 分布式存储初体验

  ```sh  
  hdfs dfs -mkdir -p /test/input   
  #本地hoome目录创建一个文件  
  cd /root  
    
  vim test.txt  
    
  hello hdfs  
    
  #上传linux文件到Hdfs  
  hdfs dfs -put /root/test.txt /test/input  
    
    
  #从Hdfs下载文件到linux本地  
  hdfs dfs -get /test/input/test.txt  
  ```

	- web查看上传的文件
![](/resource/hadoop1/assets/859200C7-ED5F-4809-B6E0-9192852EA848.png)

- 2.  MapReduce 分布式计算初体验

	- 1. 在HDFS文件系统根目录下面创建一个wcinput文件夹
	  ```sh  
	  [root@centos7-1 hadoop-2.9.2]$ hdfs dfs -mkdir /wcinput  
	  ```

	- 2. 在/root/目录下创建一个wc.txt文件(本地文件系统)

	  ```sh  
	  vi wc.txt  
	    
	  hadoop mapreduce yarn  
	  hdfs hadoop mapreduce  
	  mapreduce yarn lagou  
	  lagou  
	  lagou  
	  ```

	- 3. 上传wc.txt到Hdfs目录/wcinput下
	  ```sh  
	  hdfs dfs -put wc.txt /wcinput  
	  ```

	- 4. 执行jar指令
	  回到Hadoop目录/opt/lagou/servers/hadoop-2.9.2 执行程序  
	  ```sh  
	  hadoop jar  
	   share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar wordcount   
	  /wcinput  
	  /wcoutput  
	  ```

	- 5. 查看结果
	  查看yarn记录  
	  yarn主机所在：8088 http://centos7-3:8088  
	    
	  ```sh  
	  hdfs dfs -cat /wcoutput/part-r-00000  
	  ```

### 6. 配置历史服务器

在Yarn中运行的任务产生的日志数据不能查看，为了查看程序的历史运行情况，需要配置一下历史日志 服务器。

- 1. 配置mapred-site.xml

  ```sh  
  cd /opt/lagou/servers/hadoop-2.9.2/etc/hadoop  
    
  [root@centos7-1 hadoop]$ vi mapred-site.xml  
  ```  
    
  ```xml  
  <!-- 历史服务器端地址 -->  
  <property>  
      <name>mapreduce.jobhistory.address</name>  
      <value>centos7-1:10020</value>  
  </property>  
  <!-- 历史服务器web端地址 -->  
  <property>  
      <name>mapreduce.jobhistory.webapp.address</name>  
      <value>linux121:19888</value>  
  </property>  
  ```

- 2. 分发mapred-site.xml到其它节点
  ```sh  
  rsync-script mapred-site.xml  
  ```

- 3. 配置日志的聚集
  日志聚集:应用( Job)运行完成以后，将应用运行日志信息从各个task汇总上传到HDFS系统上。 日志聚集功能好处:可以方便的查看到程序运行详情，方便开发调试。  
    
  注意:开启日志聚集功能，需要重新启动NodeManager 、ResourceManager和 HistoryManager  
    
  ```sh  
  vim /etc/yarn-site.xml  
    
  <!-- 日志聚集功能使能 -->  
  <property>  
          <name>yarn.log-aggregation-enable</name>  
          <value>true</value>  
  </property>  
    
  <!-- 日志保留时间设置7天 -->  
  <property>  
          <name>yarn.log-aggregation.retain-seconds</name>  
          <value>604800</value>  
  </property>  
  ```  
    
  分发yarn-site.xml到集群其它节点  
  ```sh  
  rsync-script yarn-site.xml  
  ```

- 4. 启动历史服务器
  ```sh  
  [root@centos7-1 hadoop-2.9.2]$ sbin/mr-jobhistory-daemon.sh start historyserver  
  ```

- 5. 查看JobHistory
  http://centos7-1:19888/jobhistory



